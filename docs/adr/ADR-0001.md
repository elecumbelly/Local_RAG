# ADR-0001: Retrieval-Augmented Generation Stack

- **Status**: Accepted
- **Context**: We need an offline/local-first RAG stack with citation-backed chat over PDF corpora, using local models where possible and allowing optional cloud providers.
- **Decision**:
  - Use Postgres + pgvector for chunk storage and similarity search.
  - Use FastAPI for API surface (ingest, retrieve, chat, eval).
  - Use Next.js App Router for frontend.
  - Use Ollama for local embeddings/chat, with pluggable providers (OpenAI/Anthropic/Google) as fallbacks.
  - Use PDF extraction via PyPDF, with OCR via ocrmypdf when quality thresholds fail.
  - Enforce API key auth on all routes; restrict file-serving to corpus/processed roots.
  - Pin container images and dependencies; generate SBOM and run scans in CI.
- **Consequences**:
  - Requires vector extension and HNSW in Postgres.
  - OCR introduces additional dependencies and processing time but improves recall.
  - Optional cloud providers necessitate secure secret handling.
  - Need continuous monitoring of model/container updates; pinned digests recommended for production.
